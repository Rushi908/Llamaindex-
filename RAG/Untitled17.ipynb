{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5pNFK1b-GF2",
        "outputId": "9f1d61e1-61ae-4708-c239-f278bb5abb7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.31.2-py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.31.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "OPENAI_API_KEY=userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "VeShAgzd_IbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "Z0EcoH-7-9qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "bq0-FTIc-vb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxIOG-Gd-7Dv",
        "outputId": "cff9420f-9f26-4c57-c3c5-c7989e9aea97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"In the realm of code where wonders unfold,\\nThere lies a concept, recursive and bold.\\nLike a mirror reflecting itself in endless view,\\nRecursion calls upon itself, old and true.\\n\\nIt dances through functions, looping in grace,\\nEmbracing the challenge it bravely must face.\\nOne task split into fragments, small and neat,\\nRecursive calls make the solution complete.\\n\\nLike Russian dolls nestled in layers deep,\\nRecursion unwraps mysteries we seek to keep.\\nA function that calls itself, a cycle profound,\\nBringing solutions where they once were not found.\\n\\nThough some fear the infinite loop unfurled,\\nRecursion's beauty shines in the coding world.\\nWith elegance and power, it solves with art,\\nA concept engraved in every programmer's heart.\", role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"i am a happy person i am a responsible person i always make happy to everyone and i care to my family\""
      ],
      "metadata": {
        "id": "fWjuDKs0AX7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": 'Perform sentiment analysis on the given text: \"{text}\". Classify it as either Positive, Negative, or Neutral sentiment. Provide the result in JSON format with the following keys: sentiment.'\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f'Analyze the sentiment of the text \"{text}\" and categorize it as Positive, Negative, or Neutral. Return the result in JSON format with the key \"sentiment\".'\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        n=1,\n",
        "        stop=None,\n",
        "        temperature=0\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "1vK-JpJ1_WUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq_TuR-NAJrC",
        "outputId": "d59386a1-7e96-4d97-9b6e-cc342d757818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='{\\n    \"sentiment\": \"Positive\"\\n}', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"Determine the cost\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"Sam has 3 notebooks. He purchases 4 more packs of notebooks, with 5 notebooks in each pack. How many notebooks does Sam have now?\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"assistant\",\n",
        "      \"content\": \"Sam initial notebooks: 3 notebooks\\nNotebooks from the new packs: 4 packs * 5 notebooks/pack = 20 notebooks\\nNow, add these two quantities:\\n3 notebooks (initial) + 20 notebooks (new packs) = 23 notebooks\"\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": \"The basket has 30 apples. If 20 apples are used for lunch and an additional 6 are bought from the market, how many apples are there in the basket?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0,\n",
        "  max_tokens=1024,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "3gjAEovWA0UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHHhgnFEBa0e",
        "outputId": "28cd9db5-5952-4f02-d7e0-571795b1dbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apples in the basket: 30 apples\n",
            "Apples used for lunch: 20 apples\n",
            "Apples bought from the market: 6 apples\n",
            "Total apples now in the basket:\n",
            "30 apples (initial) - 20 apples (used for lunch) + 6 apples (bought) = 16 apples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Replace with your LLM API (e.g., OpenAI)\n",
        "def send_prompt_to_llm(prompt):\n",
        "  # Simulate LLM response (replace with actual API call)\n",
        "  response = \"LLM response to your prompt\"  # Placeholder\n",
        "  return response\n",
        "\n",
        "def self_consistent_cot(task, problem, num_iterations=3):\n",
        "\n",
        "  all_answers = []\n",
        "  for _ in range(num_iterations):\n",
        "    # Craft the CoT prompt\n",
        "    prompt = f\"**Task:** {task}\\n**Problem:** {problem}\\n\\n\"\n",
        "    prompt += \"**Step 1: Understand the problem.**\\n\"\n",
        "    prompt += \"  - What does it mean to {task}?\\n\"\n",
        "    prompt += \"**Step 2: Design a solution.**\\n\"\n",
        "    prompt += \"  - How can we solve this problem?\\n\"\n",
        "    prompt += \"**Step 3: Implement the solution.**\\n\"\n",
        "    prompt += \"  - Write the Python code to achieve this.\\n\"\n",
        "\n",
        "    # Send the prompt to the LLM and get a response (replace with your LLM call)\n",
        "    answer = send_prompt_to_llm(prompt)\n",
        "    all_answers.append(answer)\n",
        "\n",
        "  # Find the most common answer\n",
        "  answer_counts = {answer: all_answers.count(answer) for answer in set(all_answers)}\n",
        "  final_answer = max(answer_counts, key=answer_counts.get)\n",
        "\n",
        "  return {\n",
        "      \"task\": task,\n",
        "      \"problem\": problem,\n",
        "      \"final_answer\": final_answer,\n",
        "      \"all_answers\": all_answers\n",
        "  }\n",
        "\n",
        "# Example usage\n",
        "result = self_consistent_cot(\n",
        "    task=\"Write a Python function to reverse a string\",\n",
        "    problem=\"Hello world!\"\n",
        ")\n",
        "\n",
        "print(f\"Task: {result['task']}\")\n",
        "print(f\"Problem: {result['problem']}\")\n",
        "print(f\"Final Answer: {result['final_answer']}\")\n",
        "print(f\"All Answers: {result['all_answers']}\")\n"
      ],
      "metadata": {
        "id": "IIx_9dQXBdKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat with the Database"
      ],
      "metadata": {
        "id": "P0dsj_DuCeVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3"
      ],
      "metadata": {
        "id": "INzN3vcwChnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(\"mydatabase.db\")"
      ],
      "metadata": {
        "id": "CknCdk4OIGHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a cursor object\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Get the list of tables\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "\n",
        "# Fetch the table names\n",
        "tables = cursor.fetchall()\n"
      ],
      "metadata": {
        "id": "Je2Kso-WIIdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tables"
      ],
      "metadata": {
        "id": "TKDUTxQOIbII",
        "outputId": "3bd02311-7e71-4d27-d88c-405052cb098c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tables in the database:\")\n",
        "for table in tables:\n",
        "  print(table[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "294YVSL1ISEt",
        "outputId": "9029e674-694d-42d1-8010-a657ae626b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tables in the database:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for table in tables:\n",
        "  print(table[0])"
      ],
      "metadata": {
        "id": "IyQ7utYkIU2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h9IG31dkIaD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}